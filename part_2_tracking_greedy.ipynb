{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import cv2 \n",
    "from pa3_demo import load_obj_each_frame\n",
    "BBOX_FILE = \"part_2_frame_dict_base.json\"\n",
    "VIDEO_FILE = \"commonwealth.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy Data Association (with observation history)\n",
    "Reference: [PSU CSE598C](https://www.cse.psu.edu/~rtc12/CSE598C/datassocPart1.pdf)\n",
    "\n",
    "The goal of this task is to assign unique IDs to each of the bounding boxes in the frames of a video. We use a greedy Nearest Neighbor algorithm that favors objects with long observation histories. From the reference above, we interpret the Global Nearest Neighbor (GNN) algorithm as follows:\n",
    "1. For each frame iterate over each bounding box and store them in a history tracker\n",
    "2. The tracker is a dictionary with the bounding box ID as the key and the history as the value, and it is sorted in a descending order of the occurrence of the bounding box\n",
    "3. For each of these observed bounding boxes, IoU is calculated with the previous frame's bounding boxes with the same ID. If the IoU is greater than a threshold, the bounding box is assigned the same ID. If not, a new ID is assigned to the bounding box.\n",
    "4. Finally, the algorithm returns a dictionary of the bounding box IDs where each ID is associated with the bounding box in each frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculates Intersection over Union (IoU) between two bounding boxes.\"\"\"\n",
    "    x_min1, y_min1, w1, h1 = box1[\"x_min\"], box1[\"y_min\"], box1[\"width\"], box1[\"height\"]\n",
    "    x_min2, y_min2, w2, h2 = box2[\"x_min\"], box2[\"y_min\"], box2[\"width\"], box2[\"height\"]\n",
    "    \n",
    "    x_max1, y_max1 = x_min1 + w1, y_min1 + h1\n",
    "    x_max2, y_max2 = x_min2 + w2, y_min2 + h2\n",
    "\n",
    "    xA = max(x_min1, x_min2)\n",
    "    yA = max(y_min1, y_min2)\n",
    "    xB = min(x_max1, x_max2)\n",
    "    yB = min(y_max1, y_max2)\n",
    "\n",
    "    inter_area = max(0, xB - xA) * max(0, yB - yA)\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "\n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "    return iou\n",
    "\n",
    "def assign_objects(frames, similarity_threshold=0.5):\n",
    "    \"\"\"Assigns unique IDs to objects in video frames using Global Nearest Neighbor.\n",
    "\n",
    "    Args:\n",
    "        frames: Dictionary where keys are frame numbers and values are lists of bounding boxes.\n",
    "        similarity_threshold: Minimum IoU score for considering a match.\n",
    "\n",
    "    Returns:\n",
    "        tracks: Dictionary where keys are object IDs and values are lists of [frame_number, bounding_box].\n",
    "    \"\"\"\n",
    "    tracks = defaultdict(list)\n",
    "    \n",
    "\n",
    "    for frame_number, boxes in frames.items():\n",
    "        unassigned_boxes = []\n",
    "        for box in boxes: \n",
    "            # add box with initial observation history to unassigned_boxes\n",
    "            unassigned_boxes.append([box, 0])\n",
    "\n",
    "        # sort unassigned boxes by observation history\n",
    "        unassigned_boxes.sort(key=lambda x: x[1], reverse=True)\n",
    "        # iterate through unassigned boxes\n",
    "        for box, history in unassigned_boxes:\n",
    "            \n",
    "            best_match, best_iou = None, 0\n",
    "\n",
    "            for track_id, track in tracks.items():\n",
    "                # get the last box in the track\n",
    "                last_box = track[-1][1]\n",
    "\n",
    "                # calculate IoU between the last box in the track and the current box\n",
    "                iou = calculate_iou(last_box, box)\n",
    "\n",
    "                # update the best match if necessary\n",
    "                if iou > best_iou:\n",
    "                    best_match, best_iou = track_id, iou\n",
    "            # assign the current box to the best match (if it exists)\n",
    "            if best_iou >= similarity_threshold:\n",
    "                tracks[best_match].append([frame_number, box])\n",
    "\n",
    "                # remove the current box from unassigned_boxes\n",
    "                unassigned_boxes.remove([box, history])\n",
    "                # update the observation history of the matched box\n",
    "                tracks[best_match][-1][-1] = box\n",
    "\n",
    "            # create a new track for the current box (if no match)\n",
    "            else:\n",
    "                tracks[len(tracks) + 1].append([frame_number, box])\n",
    "                unassigned_boxes.remove([box, history])\n",
    "                unassigned_boxes.append([box, history + 1])\n",
    "\n",
    "    return tracks\n",
    "\n",
    "frame_dict = load_obj_each_frame(BBOX_FILE)\n",
    "\n",
    "output_track = assign_objects(frame_dict)\n",
    "# modify the output_track by updating the id key of frame_dict\n",
    "new_frame_dict = frame_dict.copy()\n",
    "for track_id, track in output_track.items():\n",
    "    for frame_id, box in track:\n",
    "        # print(frame_dict[frame_id][frame_dict[frame_id].index(box)])\n",
    "        new_frame_dict[frame_id][new_frame_dict[frame_id].index(box)][\"id\"] = track_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the output_track\n",
    "# for track_id, track in output_track.items():\n",
    "#     print(f\"Track {track_id}:\")\n",
    "#     for observation in track:\n",
    "#         print(f\"  - Frame {observation[0]}: {observation[1]}\")\n",
    "\n",
    "\n",
    "def draw_object(object_dict, image):\n",
    "    x_min, y_min, w, h, id= object_dict[\"x_min\"], object_dict[\"y_min\"], object_dict[\"width\"], object_dict[\"height\"], object_dict[\"id\"]\n",
    "    image = cv2.rectangle(image, (x_min, y_min), (x_min + w, y_min + h), (0, 255, 0), 2)\n",
    "    image = cv2.putText(image, f\"ID: {id}\", (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    return image\n",
    "def draw_objects_in_video(video_file,frame_dict, output_file = \"part_2_demo.mp4\"):\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    ok, image = cap.read()\n",
    "    vidwrite = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "    while ok:\n",
    "        ######!!!!#######\n",
    "        image = cv2.resize(image, (700, 500)) # make sure your video is resize to this size, otherwise the coords in the data file won't work !!!\n",
    "        ######!!!!#######\n",
    "        frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        print(frame_number)\n",
    "        objects = frame_dict.get(str(frame_number), [])\n",
    "        for obj in objects: \n",
    "            print(obj)\n",
    "            image = draw_object(obj, image)\n",
    "        vidwrite.write(image)\n",
    "        ok, image = cap.read()\n",
    "    vidwrite.release()\n",
    "    cap.release()\n",
    "draw_objects_in_video(VIDEO_FILE, new_frame_dict, output_file=\"output.mp4\")\n",
    "dumped = json.dumps(new_frame_dict)\n",
    "with open(\"part_2_frame_dict.json\" , \"w\") as f:\n",
    "    f.write(dumped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikinlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
